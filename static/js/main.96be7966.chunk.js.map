{"version":3,"sources":["components/AppNavigationBar.js","components/ImageLink.js","components/FaceRecognition.js","App.js","index.js"],"names":["AppNavigationBar","className","ImageLink","setinputLink","onButtonSubmit","type","onChange","e","preventDefault","target","value","onClick","FaceRecognition","faceBox","imageUrl","id","alt","src","style","top","topRow","right","rightCol","bottom","bottomRow","left","leftCol","app","Clarifai","App","apiKey","useState","inputLink","setimageUrl","setfaceBox","useEffect","models","predict","then","response","data","clarifaiFaceBox","outputs","regions","region_info","bounding_box","image","document","getElementById","imageWidth","Number","width","imageHeight","height","left_col","top_row","right_col","bottom_row","calculateFaceLocation","catch","err","console","log","ReactDOM","render","StrictMode"],"mappings":"wTAgBeA,EAVU,WACrB,OACI,qBAAKC,UAAU,SAAf,SAEQ,2DCiBDC,G,MAvBG,SAAC,GAAoC,IAAnCC,EAAkC,EAAlCA,aAAcC,EAAoB,EAApBA,eAO9B,OACI,qBAAKH,UAAU,aAAf,SACI,sBAAKA,UAAU,gBAAf,UACI,mBAAGA,UAAU,WAAb,SACK,wDAEL,gCACI,uBAAOI,KAAK,OAAOJ,UAAU,aAAaK,SAZnC,SAACC,GACpBA,EAAEC,iBACFL,EAAaI,EAAEE,OAAOC,UAWV,wBAAQT,UAAU,YAAYU,QAASP,EAAvC,8BCHLQ,G,MAXS,SAAC,GAAyB,IAAxBC,EAAuB,EAAvBA,QAASC,EAAc,EAAdA,SAC/B,OACI,qBAAKb,UAAU,iBAAf,SACI,sBAAKA,UAAU,eAAf,UACI,qBAAKc,GAAG,gBAAiBC,IAAK,iBAAiBC,IAAKH,IACpD,qBAAKb,UAAU,cAAciB,MAAO,CAACC,IAAKN,EAAQO,OAAQC,MAAOR,EAAQS,SAAUC,OAAQV,EAAQW,UAAWC,KAAMZ,EAAQa,kBCCtIC,G,MAAM,IAAIC,IAASC,IAAI,CAC3BC,OAAQ,sCA6DKD,MAzDf,WAEE,MAAkCE,mBAAS,IAA3C,mBAAOC,EAAP,KAAkB7B,EAAlB,KAEA,EAA+B4B,mBAAS,IAAxC,mBAAOjB,EAAP,KAAiBmB,EAAjB,KAEA,EAA6BF,mBAAS,IAAtC,mBAAOlB,EAAP,KAAgBqB,EAAhB,KAqBAC,qBAAU,WAELrB,GAAYV,OAGjB,IAAMA,EAAgB,WACpB6B,EAAYD,GAEZL,EAAIS,OACDC,QAAS,mCACRL,GAEDM,MAAK,SAAAC,GAAQ,OAAIL,EA9BQ,SAACM,GAE7B,IAAMC,EAAkBD,EAAKE,QAAQ,GAAGF,KAAKG,QAAQ,GAAGC,YAAYC,aAE9DC,EAAOC,SAASC,eAAe,iBAC/BC,EAAaC,OAAOJ,EAAMK,OAC1BC,EAAcF,OAAOJ,EAAMO,QAEjC,MAAQ,CACN3B,QAAWe,EAAgBa,SAAWL,EACtC7B,OAAUqB,EAAgBc,QAAUH,EACpC9B,SAAY2B,EAAaR,EAAgBe,UAAYP,EACrDzB,UAAa4B,EAAeX,EAAgBgB,WAAaL,GAkB5BM,CAAsBnB,OAClDoB,OAAM,SAAAC,GAAG,OAAIC,QAAQC,IAAIF,OAI9B,OACE,sBAAK3D,UAAU,YAAf,UACE,cAAC,EAAD,CAAkBA,UAAU,WAC5B,cAAC,EAAD,CACEE,aAAcA,EACdC,eAAgBA,IAElB,cAAC,EAAD,CAAiBS,QAASA,EAASC,SAAUA,Q,YC1DnDiD,IAASC,OACP,cAAC,IAAMC,WAAP,UACE,cAAC,EAAD,MAEFlB,SAASC,eAAe,W","file":"static/js/main.96be7966.chunk.js","sourcesContent":["\r\n\r\nimport '../css/AppNavigationBar.css';\r\n\r\n\r\n\r\nconst AppNavigationBar = () => {\r\n    return (\r\n        <nav className='NavBar'>\r\n            \r\n                <span >Face Recognition App</span>\r\n            \r\n        </nav>\r\n    );\r\n}\r\n\r\nexport default AppNavigationBar;","\r\n\r\nimport '../css/ImageLink.css';\r\n\r\nconst ImageLink = ({setinputLink, onButtonSubmit}) => {\r\n    \r\n   const handleLinkChange =(e) =>{\r\n        e.preventDefault();\r\n        setinputLink(e.target.value);\r\n    }\r\n\r\n    return (\r\n        <div className='uploadForm'>\r\n            <div className='FormContainer'>\r\n                <p className='textForm'>\r\n                    {'you can detect a face on any image giving the link '}\r\n                </p>\r\n                <div>\r\n                    <input type='text' className='Input-text' onChange={handleLinkChange}></input>\r\n                    <button className='Btndetect' onClick={onButtonSubmit}>Detect</button>\r\n                </div>\r\n            </div>\r\n            \r\n        </div>\r\n    );\r\n}\r\n\r\nexport default ImageLink;","\r\n\r\nimport '../css/FaceRecognition.css'\r\n\r\n\r\nconst FaceRecognition = ({faceBox, imageUrl}) => {\r\n    return (\r\n        <div className='imageContainer'>\r\n            <div className='postionImage'>\r\n                <img id='imageToDetect'  alt ='face detection' src={imageUrl} />\r\n                <div className='boundingBox' style={{top: faceBox.topRow, right: faceBox.rightCol, bottom: faceBox.bottomRow, left: faceBox.leftCol}}></div>\r\n            </div>\r\n        </div>\r\n    );\r\n}\r\n\r\nexport default FaceRecognition;","import { useEffect, useState } from 'react';\nimport Clarifai from 'clarifai';\nimport AppNavigationBar from './components/AppNavigationBar';\nimport ImageLink from './components/ImageLink';\nimport FaceRecognition from './components/FaceRecognition';\n\n\nimport './css/App.css';\n\n\n//declare the app for clarifai API\nconst app = new Clarifai.App({\n  apiKey: 'dbeb1da5516048aeabeefa556df86170'\n });\n\n\nfunction App() {\n  // declare a new state variable for the input of the image link\n  const [inputLink, setinputLink] = useState('');\n  //ONCE the user click on detect we will have this state to show the image on the page\n  const [imageUrl, setimageUrl]= useState('');\n  //faceBox is a state where we have the 4 point of the bounding box of the face\n  const [faceBox, setfaceBox]= useState({});\n  \n  // calculateFaceLocation is a function that giving the response from clarifai will calculate the placement of for points frame of the face\n  const calculateFaceLocation = (data) =>{\n    //the data is the response of clarifai we extract the for point of face \n    const clarifaiFaceBox = data.outputs[0].data.regions[0].region_info.bounding_box;\n    // the image on our page don't have a fixed width and heught so we have to extract them \n    const image= document.getElementById('imageToDetect');\n    const imageWidth = Number(image.width);\n    const imageHeight = Number(image.height);\n    //we will calculate the placement of the for point of the bounding box\n    return( {\n      leftCol : (clarifaiFaceBox.left_col * imageWidth),\n      topRow : (clarifaiFaceBox.top_row * imageHeight),\n      rightCol : (imageWidth -(clarifaiFaceBox.right_col * imageWidth)),\n      bottomRow : (imageHeight - (clarifaiFaceBox.bottom_row * imageHeight))\n    }) \n    \n  }\n  \n  //when we change the window width it will recalculate the frame of the face because the width of picture will change \n  useEffect(()=>{\n    //the change will have to happen just when we have an image shown on the page \n    if(imageUrl) { onButtonSubmit()}\n  });\n\n  const onButtonSubmit =() =>{\n    setimageUrl(inputLink);\n    // we send the image link to the face detection model of clarifai\n    app.models\n      .predict( \"a403429f2ddf4b49b307e318f00e528b\",\n        inputLink)\n        //after we get the response of clarifai we have to calculate the placement of the for point of the bounding box and change the state faceBox\n      .then(response => setfaceBox(calculateFaceLocation(response)))\n      .catch(err => console.log(err));\n  };\n\n\n  return (\n    <div className=\"container\">\n      <AppNavigationBar className=\"Navbar\"/>\n      <ImageLink  \n        setinputLink={setinputLink} \n        onButtonSubmit={onButtonSubmit}\n        />\n      <FaceRecognition faceBox={faceBox} imageUrl={imageUrl}/>\n      \n    </div>\n  );\n}\n\nexport default App;\n","import React from 'react';\nimport ReactDOM from 'react-dom';\nimport App from './App';\n\nimport 'normalize.css';\nimport './css/index.css';\n\n\n\nReactDOM.render(\n  <React.StrictMode>\n    <App />\n  </React.StrictMode>,\n  document.getElementById('root')\n);\n\n\n"],"sourceRoot":""}